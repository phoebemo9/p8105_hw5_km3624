---
title: "Homework 5"
author: "Phoebe Mo"
date: "2020-11-12"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(rvest)
library(dplyr)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = 0.6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis",
  digits = 3
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1

Read in the data

```{r}
homicide_df =
  read.csv("data/homicide-data.csv") %>%
  mutate(
    city_state = str_c(city, state, sep = "_"),
    resolved = case_when(
      disposition == "Closed without arrest" ~ "unsolved",
      disposition == "Open/No arrest" ~ "unsolved",
      disposition == "Closed by arrest" ~ "solved"
    )
  ) %>%
  select(city_state, resolved) %>%
  filter(city_state != "Tulsa_AL")
```

Look at this a bit
```{r}
aggregate_df =
  homicide_df %>%
  group_by(city_state) %>%
  summarize(
    hom_total = n(),
    hom_unsolved = sum(resolved == "unsolved")
  )
```

Prop test for single city Baltimore

```{r}
single_prop =
  prop.test(
    aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(hom_unsolved),
    aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(hom_total)) %>%
  broom::tidy()
```

Try to iterate

```{r}
results_df =
  aggregate_df %>%
  mutate(
    prop_tests = map2(.x = hom_unsolved, .y = hom_total, ~prop.test(x = .x, n = .y)),
    tidy_tests = map(.x = prop_tests, ~broom::tidy(.x))
  ) %>%
  select(-prop_tests) %>%
  unnest(tidy_tests) %>%
  select(city_state, estimate, conf.low, conf.high)
```

```{r}
results_df %>%
  mutate(city_state = fct_reorder(city_state, estimate)) %>%
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```

## Problem 2

import all the datasets, and tidy them

```{r}
path_df =
  tibble(
    path = list.files("data/problem2_data/")
  ) %>%
  mutate(path = str_c("data/problem2_data/", path)) %>%
  mutate(
    read_data = map(.x = path, ~read.csv(.x)),
    path = str_replace(path, "data/problem2_data/", ""),
    path = str_replace(path, ".csv", ""),
    subject = path
  ) %>%
  select(-path) %>%
  unnest(read_data) %>%
  pivot_longer(
    week_1:week_8,
    names_to = "week",
    values_to = "observation"
  ) %>%
  mutate(
    week = str_replace(week, "_", "")
  )
```

Make a spaghetti plot showing observations on each subject over time

```{r}
spaghetti_plot =
  path_df %>%
  ggplot(aes(x = week, y = observation, color = subject, group = subject)) +
  geom_line() + geom_point()
spaghetti_plot
```

Comment on the difference: The control subjects tend to have lower observations than the experiment subjects across these 8 weeks. For the experiment groups, they tend to increase during these weeks, while for the control groups, they tend to keep a stable fluctuation during these weeks.

## Problem 3

Run simulation when mu = 0 for 5000 times

```{r}
set.seed(1)
estimate_vec = vector("list", 5000)
p_val_vec = c()

for (i in 1:5000) {
  rand_sample = tibble(x = rnorm(30, mean = 0, sd = 5))
  test_result = t.test(rand_sample, mu = 0, alpha = 0.05)
  tidy_result = broom::tidy(test_result)
  estimate_vec[[i]] = pull(tidy_result, estimate)
  p_val_vec = append(p_val_vec, pull(tidy_result, p.value))
}

estimate_df = bind_rows(estimate_vec)
result_df =
  cbind(estimate_df, p_val_vec) %>%
  mutate(p_val = p_val_vec) %>%
  select(-p_val_vec)

```

Repeat above and run simulations for mu = 1, 2, 3, 4, 5, 6

```{r}
set.seed(1)

simulation = function(mu) {
  sim_data = tibble(x = rnorm(30, mean = mu, sd = 5))
  test_result = t.test(sim_data, mu = 0, alpha = 0.05) %>%
    broom::tidy()
  result_df = data.frame(test_result$estimate, test_result$p.value)
}

sim_results =
  tibble(mu_num = c(1, 2, 3, 4, 5, 6)) %>%
  mutate(
    output_lists = map(.x = mu_num, ~rerun(5000, simulation(.x))),
    estimate_dfs = map(output_lists, bind_rows)
  ) %>%
  select(-output_lists) %>%
  unnest(estimate_dfs) %>%
  rename(
    estimate = test_result.estimate,
    p_val = test_result.p.value
  )
```

Make a plot showing the proportion of times the null was rejected (the power of the test) on the y axis and the true value of μ on the x axis. Describe the association between effect size and power.

```{r}
sim_results %>%
  group_by(mu_num) %>%
  summarize(rejected_num = sum(p_val < 0.05) / 5000) %>%
  ggplot(aes(x = mu_num, y = rejected_num)) +
  geom_point() + geom_line() +
  labs(title = "Proportion of Rejections of Null", x = "Real Mean", y = "Proportion") +
  theme(plot.title = element_text(size = 15, hjust = 0.5))
```

By observing the plot, we find that when the effect size increases, the power of the test increases.

Now, make a plot showing the average estimate of μ̂  on the y axis and the true value of μ on the x axis

```{r}
sim_results %>%
  group_by(mu_num) %>%
  summarize(mean_mu = mean(estimate)) %>%
  ggplot(aes(x = mu_num, y = mean_mu)) +
  geom_point() + geom_line() +
  labs(title = "Average Estimate of Mu vs True Mu", x = "True Mu", y = "Average Estimate") +
  theme(plot.title = element_text(size = 15, hjust = 0.5))
  
```

Make a second plot of the average estimate of μ̂  only in samples for which the null was rejected on the y axis and the true value of μ on the x axis. Is the sample average of μ̂  across tests for which the null is rejected approximately equal to the true value of μ? Why or why not?

```{r}
sim_results %>%
  filter(p_val < 0.05) %>%
  group_by(mu_num) %>%
  summarize(mean_mu = mean(estimate)) %>%
  ggplot(aes(x = mu_num, y = mean_mu)) +
  geom_point() + geom_line() +
  labs(title = "Average Estimate of Mu (rejected) vs True Mu", x = "True Mu", y = "Average Estimate (rejected)") +
  theme(plot.title = element_text(size = 15, hjust = 0.5))
  
```

The sample average of μ̂  across tests for which the null is rejected approximately equal to the true value of μ. In this problem, we are doing t-test with null hypothesis "the true mean is equal to 0". When rejecting the null, that says the values rejected are not in an acceptable range for our null hypothesis (mu = 0), but these values will be closed to the real mean (1, 2, 3, 4, 5, 6).